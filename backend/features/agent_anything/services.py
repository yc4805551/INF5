import requests
import os
import logging
import json

# Configuration
ANYTHING_API_BASE = os.getenv("ANYTHING_LLM_API_BASE", "http://localhost:3001/api/v1")
ANYTHING_API_KEY = os.getenv("ANYTHING_LLM_API_KEY", "")

# Default Workspace (User should have created this)
DEFAULT_WORKSPACE = "inf_knowledge"

def get_headers():
    return {
        "Authorization": f"Bearer {ANYTHING_API_KEY}",
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

def get_anything_workspaces():
    """List all workspaces to find the valid slug"""
    url = f"{ANYTHING_API_BASE}/workspaces"
    try:
        response = requests.get(url, headers=get_headers(), timeout=10)
        response.raise_for_status()
        return response.json().get('workspaces', [])
    except Exception as e:
        logging.error(f"AnythingLLM WS List Failed: {e}")
        return []

def resolve_workspace_slug(target_name=DEFAULT_WORKSPACE):
    """Find the slug for the target workspace name"""
    workspaces = get_anything_workspaces()
    for ws in workspaces:
        if ws.get('name').lower() == target_name.lower():
            return ws.get('slug')
    
    # Fallback: return the first one if found
    if workspaces:
        return workspaces[0].get('slug')
    
    return None

def chat_with_anything(message, history=[], workspace_slug=None):
    """
    Send chat to AnythingLLM workspace.
    If workspace_slug is provided, use it directly; otherwise resolve from DEFAULT_WORKSPACE.
    Returns: { 'response': str, 'sources': list }
    """
    if not workspace_slug:
        slug = resolve_workspace_slug()
        if not slug:
            raise ValueError(f"No workspace found matching '{DEFAULT_WORKSPACE}' or system is empty.")
    else:
        slug = workspace_slug
        
    url = f"{ANYTHING_API_BASE}/workspace/{slug}/chat"
    
    # Specifically for Audit, we might want to inject context differently,
    # but for standard chat, AnythingLLM manages context via the Workspace vector DB.
    payload = {
        "message": message,
        "mode": "chat" # 'chat' uses RAG + LLM. 'query' only uses RAG.
    }
    
    try:
        response = requests.post(url, headers=get_headers(), json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()
        
        # AnythingLLM response format: { "textResponse": "...", "sources": [...] }
        # Return both response and sources
        return {
            'response': data.get('textResponse', 'No response text found.'),
            'sources': data.get('sources', [])
        }
        
    except Exception as e:
        logging.error(f"AnythingLLM Chat Failed: {e}")
        raise e

def perform_anything_audit(target_text, source_context, rules):
    """
    Executes Audit using AnythingLLM RAG.
    We simulate the Agentic flow by sending prompt chains.
    """
    slug = resolve_workspace_slug()
    if not slug:
         return {
            "status": "ERROR", 
            "message": f"Please create a workspace named '{DEFAULT_WORKSPACE}' in AnythingLLM first."
        }

    # 1. Draft Phase
    # We construct a massive prompt because we can't easily 'upload' the raw text to vector db 
    # for just this single request without polluting the repo.
    # So we treat the Audit Target as "Context in Prompt" and ask AnythingLLM to query its Knowledge Base for "Norms".
    
    draft_prompt = f"""
    [Role]
    You are an expert document auditor.
    
    [Task]
    Audit the following document text based on the Knowledge Base you have access to.
    
    [Document Content]
    {target_text}
    
    [Specific Rules/Focus]
    {rules}
    
    [Instruction]
    1. Identify any discrepancies between the document and your Knowledge Base facts.
    2. Point out specific risks.
    3. Provide a structured review report.
    """

    url = f"{ANYTHING_API_BASE}/workspace/{slug}/chat"
    
    # Step 1: Draft
    try:
        resp_draft = requests.post(url, headers=get_headers(), json={"message": draft_prompt, "mode": "chat"}, timeout=120)
        resp_draft.raise_for_status()
        draft_content = resp_draft.json().get('textResponse', '')
        
        # Step 2: Critique (Simulated Reflection)
        # We send a follow-up message in the same conversation (if session is maintained? AnythingLLM is stateless unless sessionId provided, but here single turn might be safer or we construct new prompt)
        # For simplicity/robustness, we make a second discrete call with the previous context included in prompt if needed, 
        # OR we just accept the Draft for MVP v1.
        
        # Let's do a Critique call for high quality
        critique_prompt = f"""
        [Role]
        You are a Senior Editor ("Old Yang").
        
        [Input]
        Here is a draft audit report generated by a junior auditor:
        ---
        {draft_content}
        ---
        
        [Task]
        Critique and refine this report. 
        1. Remove hallucinations.
        2. Make the tone more professional.
        3. Output the FINAL report.
        """
        
        resp_critique = requests.post(url, headers=get_headers(), json={"message": critique_prompt, "mode": "chat"}, timeout=120)
        resp_critique.raise_for_status()
        critique_content = resp_critique.json().get('textResponse', '')
        
        return {
            "status": "SUCCESS",
            "draft": draft_content,
            "critique": critique_content,
            "engine": "AnythingLLM"
        }

    except Exception as e:
        logging.error(f"Audit Chain Failed: {e}")
        return {"status": "ERROR", "message": f"AnythingLLM Error: {str(e)}"}
