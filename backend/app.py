# app.py
#
# 知识库后端服务器 (Flask + Milvus + Ollama) - v13 (最终稳定版)
#
# 描述:
# 这个版本是项目的最终稳定版，解决了 'collection not loaded' 的错误，
# 并统一了数据模型，确保所有操作（创建、更新、查询）都严格遵循
# 旧知识库的 Schema，实现了完全的向后兼容。

import os
import click
import requests
import uuid
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from flask import Flask, request, jsonify
from flask_cors import CORS
from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType
from dotenv import load_dotenv

# --- 加载环境变量 ---
load_dotenv()

# --- 配置管理 ---
MILVUS_HOST = os.getenv("MILVUS_HOST", "localhost")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost")
OLLAMA_PORT = os.getenv("OLLAMA_PORT", "11434")
OLLAMA_EMBED_API_URL = f"{OLLAMA_HOST}:{OLLAMA_PORT}/api/embeddings"
KNOWLEDGE_BASE_DIR = os.getenv("KNOWLEDGE_BASE_DIR", "./knowledge_base")
KNOWLEDGE_BASE_DIR_NOMIC = os.getenv("KNOWLEDGE_BASE_DIR_NOMIC", "./knowledge_base_nomic")
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", 500))
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", 50))
INGEST_WORKERS = int(os.getenv("INGEST_WORKERS", 8))

# --- 模型映射配置 ---
MODEL_MAPPING = {
    'gemma': 'nomic-embed-text',
    'nomic': 'nomic-embed-text',
    'qwen': 'qwen3-embedding:0.6b',
}
DEFAULT_EMBEDDING_MODEL = 'qwen3-embedding:0.6b'

# --- 日志系统 ---
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S')

# --- 初始化 ---
app = Flask(__name__)
CORS(app)

try:
    logging.info(f"正在连接到 Milvus (Host: {MILVUS_HOST}, Port: {MILVUS_PORT})...")
    connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)
    logging.info("成功连接到 Milvus。")
except Exception as e:
    logging.error(f"连接 Milvus 失败: {e}")

# --- 辅助函数 ---
def get_model_for_collection(collection_name: str) -> str:
    for key, model_name in MODEL_MAPPING.items():
        if key in collection_name:
            logging.info(f"集合 '{collection_name}' 匹配到关键词 '{key}'，使用模型: '{model_name}'")
            return model_name
    logging.info(f"集合 '{collection_name}' 未匹配到任何关键词，使用默认模型: '{DEFAULT_EMBEDDING_MODEL}'")
    return DEFAULT_EMBEDDING_MODEL

def get_ollama_embedding(text: str, model_name: str):
    try:
        payload = {"model": model_name, "prompt": text}
        response = requests.post(OLLAMA_EMBED_API_URL, json=payload, timeout=60)
        response.raise_for_status()
        response_data = response.json()
        if "embedding" not in response_data:
            raise ValueError(f"Ollama API 响应 (模型: {model_name}) 中缺少 'embedding' 字段。")
        return response_data["embedding"]
    except requests.exceptions.RequestException as e:
        logging.error(f"调用 Ollama API (模型: {model_name}) 失败: {e}")
        raise RuntimeError(f"无法连接到 Ollama 服务。")
    except Exception as e:
        logging.error(f"从 Ollama (模型: {model_name}) 获取嵌入时出错: {e}")
        raise

# --- [核心修正] 统一创建与旧 Schema 一致的集合 ---
def create_milvus_collection(collection_name, dim):
    if utility.has_collection(collection_name):
        return Collection(collection_name)
    logging.info(f"集合 '{collection_name}' 不存在，正在创建 (维度: {dim})...")
    fields = [
        FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=36, is_primary=True),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="source_file", dtype=DataType.VARCHAR, max_length=1024),
        FieldSchema(name="chunk_index", dtype=DataType.INT64),
        FieldSchema(name="full_path", dtype=DataType.VARCHAR, max_length=4096),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim)
    ]
    schema = CollectionSchema(fields, description=f"知识库集合: {collection_name}")
    collection = Collection(name=collection_name, schema=schema)
    index_params = {"metric_type": "COSINE", "index_type": "IVF_FLAT", "params": {"nlist": 128}}
    collection.create_index(field_name="embedding", index_params=index_params)
    return collection

def text_to_chunks(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):
    if not text: return []
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - overlap
    return chunks

# --- [核心修正] 统一数据处理逻辑 ---
def upsert_file_to_milvus(file_path: str, collection_name: str, model_name: str):
    """
    一个通用的函数，负责处理单个文件的读取、切块、生成嵌入和插入/更新到Milvus。
    在所有操作前加载集合，并严格按照旧 Schema 准备数据。
    """
    filename = os.path.basename(file_path)
    
    try:
        collection = Collection(collection_name)
        collection.load() # <-- [修复] 确保集合已加载
        
        # 1. 删除旧数据
        delete_expr = f"source_file == '{filename}'"
        collection.delete(delete_expr)
        logging.info(f"已从 '{collection_name}' 中删除 '{filename}' 的旧条目。")

        # 2. 准备新数据
        with open(file_path, 'r', encoding='utf-8') as f: content = f.read()
        chunks = text_to_chunks(content)
        if not chunks: 
            logging.info(f"文件 '{filename}' 为空，无需插入新数据。")
            return
        
        entities_to_insert = []
        logging.info(f"为 '{filename}' 的 {len(chunks)} 个文本块并发生成嵌入 (使用 {INGEST_WORKERS} 个工作线程)...")
        with ThreadPoolExecutor(max_workers=INGEST_WORKERS) as executor:
            future_to_chunk = {executor.submit(get_ollama_embedding, chunk, model_name): (i, chunk) for i, chunk in enumerate(chunks)}
            for future in as_completed(future_to_chunk):
                try:
                    embedding = future.result()
                    i, chunk = future_to_chunk[future]
                    
                    # 严格按照旧 Schema 构建实体
                    entity = {
                        "id": str(uuid.uuid4()),
                        "text": chunk,
                        "source_file": filename,
                        "chunk_index": i,
                        "full_path": file_path,
                        "embedding": embedding
                    }
                    entities_to_insert.append(entity)
                except Exception as e:
                    logging.error(f"为 '{filename}' 的一个文本块生成嵌入时失败: {e}")

        # 3. 批量插入
        if entities_to_insert:
            collection.insert(entities_to_insert)
            collection.flush()
            logging.info(f"成功为 '{filename}' 插入 {len(entities_to_insert)} 个新条目。")
            
    except Exception as e:
        logging.error(f"处理文件 '{filename}' 时发生严重错误: {e}")
    finally:
        # 确保操作完成后释放集合资源
        if 'collection' in locals():
            collection.release()

def process_file_delete(file_path, collection_name):
    filename = os.path.basename(file_path)
    logging.info(f"检测到文件删除: {filename}")
    try:
        collection = Collection(collection_name)
        collection.load() # <-- [修复] 确保集合已加载
        delete_expr = f"source_file == '{filename}'"
        collection.delete(delete_expr)
        logging.info(f"已从 '{collection_name}' 中删除 '{filename}' 的所有相关条目。")
    except Exception as e:
        logging.error(f"删除文件 '{filename}' 的条目时失败: {e}")
    finally:
        if 'collection' in locals():
            collection.release()

# --- 文件监控处理器 ---
class KnowledgeBaseEventHandler(FileSystemEventHandler):
    def __init__(self, collection_to_watch, model_name, base_dir=None):
        self.collection_to_watch = collection_to_watch
        self.model_name = model_name
        self.base_dir = base_dir or KNOWLEDGE_BASE_DIR
        self.watch_path = os.path.normpath(os.path.join(self.base_dir, self.collection_to_watch))
        logging.info(f"监控器已初始化，目标路径: {self.watch_path}")

    def process_if_relevant(self, event):
        if event.is_directory or not (event.src_path.endswith(".txt") or event.src_path.endswith(".md")):
            return
        
        event_dir = os.path.normpath(os.path.dirname(event.src_path))
        if event_dir != self.watch_path:
            return

        if event.event_type in ('created', 'modified'):
            upsert_file_to_milvus(event.src_path, self.collection_to_watch, self.model_name)
        elif event.event_type == 'deleted':
            process_file_delete(event.src_path, self.collection_to_watch)
        elif event.event_type == 'moved':
            process_file_delete(event.src_path, self.collection_to_watch)
            dest_dir = os.path.normpath(os.path.dirname(event.dest_path))
            if dest_dir == self.watch_path:
                upsert_file_to_milvus(event.dest_path, self.collection_to_watch, self.model_name)

    def on_created(self, event): self.process_if_relevant(event)
    def on_modified(self, event): self.process_if_relevant(event)
    def on_deleted(self, event): self.process_if_relevant(event)
    def on_moved(self, event): self.process_if_relevant(event)


# --- 数据导入逻辑 ---
def ingest_data():
    if not os.path.exists(KNOWLEDGE_BASE_DIR) or not os.path.isdir(KNOWLEDGE_BASE_DIR):
        logging.error(f"知识库根目录 '{KNOWLEDGE_BASE_DIR}' 不存在或不是一个目录。")
        return

    for collection_name in os.listdir(KNOWLEDGE_BASE_DIR):
        collection_path = os.path.join(KNOWLEDGE_BASE_DIR, collection_name)
        if not os.path.isdir(collection_path): continue

        logging.info(f"\n--- 正在处理目录 (集合): {collection_name} ---")
        model_to_use = get_model_for_collection(collection_name)
        
        try:
            logging.info(f"正在检测模型 '{model_to_use}' 的向量维度...")
            dummy_embedding = get_ollama_embedding("test", model_to_use)
            dim = len(dummy_embedding)
            logging.info(f"检测到维度为: {dim}")
        except Exception as e:
            logging.error(f"无法为模型 '{model_to_use}' 获取向量维度，跳过此目录。错误: {e}")
            continue

        create_milvus_collection(collection_name, dim)

        for filename in os.listdir(collection_path):
            file_path = os.path.join(collection_path, filename)
            if not (filename.endswith(".txt") or filename.endswith(".md")): continue
            logging.info(f"开始处理文件: {filename}")
            upsert_file_to_milvus(file_path, collection_name, model_to_use)

# --- Flask CLI 命令 ---
@app.cli.command("ingest")
def ingest_command():
    ingest_data()
    click.echo("数据导入过程完成。")

@app.cli.command("watch")
def watch_command():
    collection_to_watch = 'kb_qwen_0_6b'
    model_name = get_model_for_collection(collection_to_watch)
    
    if not utility.has_collection(collection_to_watch):
        click.echo(f"错误: 目标知识库 '{collection_to_watch}' 在 Milvus 中不存在。")
        click.echo(f"请先运行 'flask ingest' 来创建和初始化所有知识库。")
        return

    path_to_watch = KNOWLEDGE_BASE_DIR
    event_handler = KnowledgeBaseEventHandler(collection_to_watch, model_name)
    observer = Observer()
    observer.schedule(event_handler, path_to_watch, recursive=True)
    
    click.echo(f"✅ 已启动监控服务，只处理对 '{collection_to_watch}' 知识库的更新。")
    click.echo(f"   监控目录: {os.path.join(path_to_watch, collection_to_watch)}")
    click.echo("   按 Ctrl+C 停止服务。")
    
    observer.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()
    click.echo("\n监控服务已停止。")

@app.cli.command("watch-nomic")
def watch_nomic_command():
    collection_to_watch = 'kb_nomic'
    model_name = get_model_for_collection(collection_to_watch)
    
    if not utility.has_collection(collection_to_watch):
        click.echo(f"错误: 目标知识库 '{collection_to_watch}' 在 Milvus 中不存在。")
        click.echo(f"请先运行 'flask ingest' 来创建和初始化所有知识库。")
        return

    path_to_watch = KNOWLEDGE_BASE_DIR_NOMIC
    event_handler = KnowledgeBaseEventHandler(collection_to_watch, model_name, base_dir=KNOWLEDGE_BASE_DIR_NOMIC)
    observer = Observer()
    observer.schedule(event_handler, path_to_watch, recursive=True)
    
    click.echo(f"✅ 已启动监控服务，只处理对 '{collection_to_watch}' 知识库的更新。")
    click.echo(f"   监控目录: {os.path.join(path_to_watch, collection_to_watch)}")
    click.echo("   按 Ctrl+C 停止服务。")
    
    observer.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()
    click.echo("\n监控服务已停止。")


# --- API 端点 ---
@app.route('/list-collections', methods=['GET'])
def list_collections():
    try:
        collections = utility.list_collections()
        return jsonify({"collections": collections})
    except Exception as e:
        logging.error(f"API /list-collections 失败: {e}")
        return jsonify({"error": "无法获取 Milvus 集合列表", "details": str(e)}), 500

@app.route('/find-related', methods=['POST'])
def find_related():
    try:
        data = request.get_json()
        query_text = data.get('text')
        collection_name = data.get('collection_name')
        top_k = data.get('top_k', 10)

        if not query_text or not collection_name:
            return jsonify({"error": "请求中缺少 'text' 或 'collection_name'"}), 400
        
        if not utility.has_collection(collection_name):
            return jsonify({"error": f"知识库 (集合) '{collection_name}' 不存在。"}), 404

        model_to_use = get_model_for_collection(collection_name)
        query_embedding = get_ollama_embedding(query_text, model_to_use)
        
        collection = Collection(collection_name)
        collection.load()
        schema_fields = {field.name: field for field in collection.schema.fields}
        
        output_fields = ["text", "source_file", "chunk_index", "full_path"]
        
        search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
        results = collection.search(data=[query_embedding], anns_field="embedding", param=search_params, limit=top_k, output_fields=output_fields)

        response_data = []
        for hit in results[0]:
            entity = hit.entity
            response_data.append({
                "source_file": entity.get("source_file", "Unknown Source"),
                "content_chunk": entity.get("text", ""),
                "score": hit.distance,
            })

        collection.release()
        return jsonify({"related_documents": response_data})

    except (RuntimeError, ValueError) as e:
        return jsonify({"error": str(e)}), 503
    except Exception as e:
        logging.error(f"API /find-related 发生内部错误: {e}", exc_info=True)
        return jsonify({"error": "服务器内部错误", "details": str(e)}), 500

@app.route('/', methods=['GET'])
def index():
    return "知识库后端服务器正在运行 (Ollama + Milvus) v13。"

if __name__ == '__main__':
    app.run(debug=True, port=5000)

